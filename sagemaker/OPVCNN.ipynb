{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7ff16ff91dd0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import torch\n",
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorch\n",
    "import boto3\n",
    "from io import BytesIO\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../py-conjugated/networks/'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "import morphology_networks as net\n",
    "import model_training as train\n",
    "import model_testing as test\n",
    "import physically_informed_loss_functions as PhysLoss\n",
    "import network_utils as nuts\n",
    "\n",
    "torch.manual_seed(28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = 'sagemaker-us-east-2-362637960691'\n",
    "train_data_location = 'py-conjugated/m2py_labels/OPV_labels/train_set/'\n",
    "test_data_location = 'py-conjugated/m2py_labels/OPV_labels/test_set/'\n",
    "model_states_location = 'py-conjugated/model_states/OPV/'\n",
    "\n",
    "client = boto3.client('s3')\n",
    "resource = boto3.resource('s3')\n",
    "s3_bucket = resource.Bucket(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set/\n",
      "train_set/100C_15min_Sub4_Dev2_labels.npy\n",
      "train_set/100C_30min_Sub7_Dev4_labels.npy\n",
      "train_set/100C_30min_Sub7_Dev7_labels.npy\n",
      "train_set/100C_5min_Sub1_Dev3_labels.npy\n",
      "train_set/125C_15min_Sub4_Dev1_labels.npy\n",
      "train_set/125C_15min_Sub4_Dev2_labels.npy\n",
      "train_set/125C_15min_Sub4_Dev6_labels.npy\n",
      "train_set/125C_15min_Sub4_postexam_labels.npy\n",
      "train_set/125C_30min_Sub8_Dev3_labels.npy\n",
      "train_set/125C_5min_Sub1_Dev2_labels.npy\n",
      "train_set/125C_5min_Sub1_Dev3_labels.npy\n",
      "train_set/150C_15min_Sub4_Dev1_labels.npy\n",
      "train_set/150C_15min_Sub4_Dev7_labels.npy\n",
      "train_set/150C_30min_Sub7_Dev3_labels.npy\n",
      "train_set/150C_5min_Sub1_Dev7_labels.npy\n",
      "train_set/175C_15min_Sub4_Dev2_labels.npy\n",
      "train_set/175C_15min_Sub4_Dev3_labels.npy\n",
      "train_set/175C_30min_Sub8_Dev6_labels.npy\n",
      "train_set/175C_30min_Sub8_Dev8_labels.npy\n",
      "train_set/175C_5min_Sub2_Dev1_labels.npy\n",
      "train_set/175C_5min_Sub2_Dev3_labels.npy\n",
      "train_set/175C_5min_Sub2_postexam_labels.npy\n",
      "train_set/2018-06-29_P3HT-PCBM_NOANNEAL_S1_D1_labels.npy\n",
      "train_set/2018-06-29_P3HT-PCBM_NOANNEAL_S1_D4_labels.npy\n",
      "train_set/2018-06-29_P3HT-PCBM_NOANNEAL_S2_D1_labels.npy\n",
      "train_set/2018-06-29_P3HT-PCBM_NOANNEAL_S3_D1_labels.npy\n",
      "test_set/\n",
      "test_set/100C_15min_Sub4_Dev2_labels.npy\n",
      "test_set/100C_15min_Sub4_Dev4_labels.npy\n",
      "test_set/100C_15min_Sub4_Dev7_labels.npy\n",
      "test_set/100C_30min_Sub7_Dev2_labels.npy\n",
      "test_set/100C_30min_Sub7_Dev4_labels.npy\n",
      "test_set/100C_30min_Sub7_Dev7_labels.npy\n",
      "test_set/100C_5min_Sub1_Dev3_labels.npy\n",
      "test_set/100C_5min_Sub1_Dev4_90D_labels.npy\n",
      "test_set/100C_5min_Sub1_Dev4_labels.npy\n",
      "test_set/125C_15min_Sub4_Dev1_labels.npy\n"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "\n",
    "train_data = nuts.OPV_ImDataset(bucket_name, train_data_location)\n",
    "test_data = nuts.OPV_ImDataset(bucket_name, test_data_location)\n",
    "\n",
    "train_data_loader = torch.utils.data.DataLoader(dataset = train_data, batch_size = len(train_data), shuffle = True)\n",
    "test_data_loader = torch.utils.data.DataLoader(dataset = test_data, batch_size = len(test_data), shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_dict = {\n",
    "    'epochs': 500\n",
    "}\n",
    "\n",
    "inputs = sagemaker_session.upload_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = PyTorch(entry_point = '../py-conjugated/networks/morphology_networks.py',\n",
    "                    role = role,\n",
    "                    framework_version = '1.4.0',\n",
    "                    source_dir = '../../py-conjugated/networks/',\n",
    "                    train_instance_count = 4,\n",
    "                    train_instance_type ='ml.p2.xlarge',\n",
    "                    hyperparameters = params_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No file named \"morphology_networks.py\" was found in directory \"../../py-conjugated/networks/\".",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-6b4c7cd170ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'training'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m         \"\"\"\n\u001b[0;32m--> 472\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_for_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_TrainingJob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36m_prepare_for_training\u001b[0;34m(self, job_name)\u001b[0m\n\u001b[1;32m   1647\u001b[0m         \u001b[0;31m# source directory. We are intentionally not handling it because this is a critical error.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1648\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource_dir\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource_dir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"s3://\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1649\u001b[0;31m             \u001b[0mvalidate_source_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentry_point\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1651\u001b[0m         \u001b[0;31m# if we are in local mode with local_code=True. We want the container to just\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/fw_utils.py\u001b[0m in \u001b[0;36mvalidate_source_dir\u001b[0;34m(script, directory)\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             raise ValueError(\n\u001b[0;32m--> 388\u001b[0;31m                 \u001b[0;34m'No file named \"{}\" was found in directory \"{}\".'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscript\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m             )\n\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No file named \"morphology_networks.py\" was found in directory \"../../py-conjugated/networks/\"."
     ]
    }
   ],
   "source": [
    "estimator.fit({'training': train_data_loader})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "num_epochs = 10\n",
    "im_learning_rate = 0.008\n",
    "\n",
    "# Device configuration (GPU if available, otherwise CPU)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 266721280000 bytes. Error code 12 (Cannot allocate memory)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-30917bbdf843>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mim_branch_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOPV_m2py_NN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#define the loss function and the optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mim_criterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mim_optimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim_branch_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim_learning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SageMaker/py-conjugated/py-conjugated/networks/morphology_networks.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, im_z)\u001b[0m\n\u001b[1;32m    107\u001b[0m         self.layer3 = nn.Sequential(\n\u001b[1;32m    108\u001b[0m             \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m               \u001b[0;31m#helps avoid over-fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m             \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6668032\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m             \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_features, out_features, bias)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0min_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 266721280000 bytes. Error code 12 (Cannot allocate memory)\n"
     ]
    }
   ],
   "source": [
    "im_branch_model = net.OPV_m2py_NN(2)\n",
    "\n",
    "#define the loss function and the optimizer\n",
    "im_criterion = nn.CrossEntropyLoss()\n",
    "im_optimizer = torch.optim.Adam(im_branch_model.parameters(), lr = im_learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "im_train_epoch_losses = []\n",
    "im_test_epoch_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # First Train the image branch\n",
    "    im_train_epoch_loss = train.train_OPV_m2py_model(model = im_branch_model,\n",
    "                                   training_data_set = im_training_data_set,\n",
    "                                   criterion = im_criterion,\n",
    "                                   optimizer = im_optimizer)\n",
    "    \n",
    "    im_train_epoch_losses.append(im_train_epoch_loss)\n",
    "    \n",
    "    im_test_epoch_loss = test.eval_OPV_m2py_model(model = im_branch_model,\n",
    "                                 testing_data_set = im_testing_data_set,\n",
    "                                 criterion = im_criterion)\n",
    "    \n",
    "    im_test_epoch_losses.append(im_test_epoch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (8,6))\n",
    "\n",
    "epochs = np.arange(1, (num_epochs+1), 1)\n",
    "\n",
    "plt.plot(epochs, im_train_epoch_losses, c = 'k', label = 'training error')\n",
    "plt.plot(epochs, im_test_epoch_losses, c = 'r', label = 'testing error')\n",
    "plt.legend(loc = 'upper right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

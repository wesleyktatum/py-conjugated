{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import sagemaker\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../py-conjugated/networks/'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "import morphology_networks as net\n",
    "import model_training as train\n",
    "import model_testing as test\n",
    "import physically_informed_loss_functions as PhysLoss\n",
    "import network_utils as nuts\n",
    "\n",
    "torch.manual_seed(28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = 'sagemaker/OPVCNN/'\n",
    "\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data_location = 's3://362637960691-dlt-utilization/py-conjugated/m2py_labels/OPV_labels/'\n",
    "model_states_location = 's3://362637960691-dlt-utilization/py-conjugated/model_states/OPV/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_filepaths = os.listdir(im_directory)\n",
    "# print (im_filepaths)\n",
    "\n",
    "files = []\n",
    "\n",
    "for fl in im_filepaths:\n",
    "    if fl[-1] == 'v':\n",
    "        pass\n",
    "    elif fl[-1] == 'e':\n",
    "        pass\n",
    "    else:\n",
    "        files.append(fl)\n",
    "        \n",
    "print (len(files))\n",
    "print (files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dict = {} # Hold all the image-like data\n",
    "im_labels = {} # Gather all the processing conditions to be the predicted feature\n",
    "\n",
    "for i,fl in enumerate(files):\n",
    "    \n",
    "    anl_temp = 0\n",
    "    anl_time = 0\n",
    "    \n",
    "    if i < len(files)-1:\n",
    "        if fl[:-6] == files[i+1][:-6]:\n",
    "            seg1 = np.load(im_directory+fl)\n",
    "            seg2 = np.load(im_directory+files[i+1])\n",
    "            sample = np.stack([seg1, seg2], axis = -1)\n",
    "            sample = sample.astype(np.double)\n",
    "#             print (sample.dtype)\n",
    "            \n",
    "            im_index = len(image_dict)\n",
    "            \n",
    "            image_dict[im_index] = sample\n",
    "            \n",
    "            if 'NOANNEAL' in fl:\n",
    "                im_labels[i] = [anl_temp, anl_time]\n",
    "\n",
    "            else:\n",
    "                temp_stop_indx = fl.index('C')\n",
    "                anl_temp = int(fl[:temp_stop_indx])\n",
    "                \n",
    "                time_start_indx = temp_stop_indx+2\n",
    "                time_stop_indx = fl.index('m')\n",
    "                time_stop_indx = time_stop_indx\n",
    "                anl_time = fl[time_start_indx:time_stop_indx]\n",
    "                anl_time = int(anl_time)\n",
    "\n",
    "                im_labels[i] = [anl_temp, anl_time]\n",
    "\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "im_labels_df = pd.DataFrame.from_dict(im_labels, orient = 'index')\n",
    "    \n",
    "print (len(image_dict))\n",
    "print (image_dict[0].shape)\n",
    "print (im_labels_df.shape)\n",
    "im_labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_im = image_dict #input features used to make prediction\n",
    "Y_im = im_labels_df #target features to be predicted\n",
    "\n",
    "x_im_train, x_im_test, y_im_train, y_im_test = train_test_split(X_im,Y_im, test_size = 0.2, shuffle = True) #split dataset into separate testing and training datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "num_epochs = 10\n",
    "im_batch_size = int(len(x_im_train[0])*0.9) # 90% of x_train samples\n",
    "im_learning_rate = 0.008\n",
    "\n",
    "# Device configuration (GPU if available, otherwise CPU)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_im_train_tensor = torch.tensor(x_im_train).float() #for conv2d, inputs need to be doubles\n",
    "y_im_train_tensor = torch.tensor(y_im_train.values.astype(np.float32)).float()#convert pd.DataFrame -> np.ndarray -> torch.tensor\n",
    "x_im_train_tensor = x_im_train_tensor.view(28, 2, 256, 256) #convert tensor of size [28, 256, 256, 2] to [28, 2, 256, 256] to fit Conv2D parameters\n",
    "im_train_tensor = torch.utils.data.TensorDataset(x_im_train_tensor, y_im_train_tensor) #create tensor with features and targets\n",
    "im_training_data_set = torch.utils.data.DataLoader(dataset = im_train_tensor, batch_size = im_batch_size, shuffle = True) #create iterable dataset with batches\n",
    "\n",
    "x_im_test_tensor = torch.tensor(x_im_test).float()\n",
    "y_im_test_tensor = torch.tensor(y_im_test.values.astype(np.float32)).float()\n",
    "x_im_test_tensor = x_im_test_tensor.view(8, 2, 256, 256) #convert tensor of size [8, 256, 256, 2] to [8, 2, 256, 256] to fit Conv2D parameters\n",
    "im_test_tensor = torch.utils.data.TensorDataset(x_im_test_tensor, y_im_test_tensor)\n",
    "im_testing_data_set = torch.utils.data.DataLoader(dataset = im_test_tensor, batch_size = im_batch_size, shuffle = True)\n",
    "\n",
    "\n",
    "im_x, im_y, im_z = X_im[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_branch_model = net.OPV_m2py_NN(im_z)\n",
    "\n",
    "#define the loss function and the optimizer\n",
    "im_criterion = nn.CrossEntropyLoss()\n",
    "im_optimizer = torch.optim.Adam(im_branch_model.parameters(), lr = im_learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "im_train_epoch_losses = []\n",
    "im_test_epoch_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # First Train the image branch\n",
    "    im_train_epoch_loss = train.train_OPV_m2py_model(model = im_branch_model,\n",
    "                                   training_data_set = im_training_data_set,\n",
    "                                   criterion = im_criterion,\n",
    "                                   optimizer = im_optimizer)\n",
    "    \n",
    "    im_train_epoch_losses.append(im_train_epoch_loss)\n",
    "    \n",
    "    im_test_epoch_loss = test.eval_OPV_m2py_model(model = im_branch_model,\n",
    "                                 testing_data_set = im_testing_data_set,\n",
    "                                 criterion = im_criterion)\n",
    "    \n",
    "    im_test_epoch_losses.append(im_test_epoch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (8,6))\n",
    "\n",
    "epochs = np.arange(1, (num_epochs+1), 1)\n",
    "\n",
    "plt.plot(epochs, im_train_epoch_losses, c = 'k', label = 'training error')\n",
    "plt.plot(epochs, im_test_epoch_losses, c = 'r', label = 'testing error')\n",
    "plt.legend(loc = 'upper right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

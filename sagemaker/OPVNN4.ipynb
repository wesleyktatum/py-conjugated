{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorch\n",
    "from sagemaker.tuner import ContinuousParameter, HyperparameterTuner\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../py-conjugated/'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "import morphology_networks as net\n",
    "import model_training as train\n",
    "import model_testing as test\n",
    "import physically_informed_loss_functions as pilf\n",
    "import network_utils as nuts\n",
    "\n",
    "torch.manual_seed(28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bucket = 'sagemaker-us-east-2-362637960691'\n",
    "train_data_path = 'py-conjugated/raw_data/OPV/train_set/'\n",
    "test_data_path = 'py-conjugated/raw_data/OPV/test_set/'\n",
    "# model_states_path = 's3://{}/py_conjugated/model_states/OPV/OPV_encoder_1/'.format(data_bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "train_dataset = nuts.OPV_ImDataset(data_bucket, train_data_path)\n",
    "test_dataset = nuts.OPV_ImDataset(data_bucket, test_data_path)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size = 26)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, criterion, lr, epochs = 30):\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "    \n",
    "    train_epoch_pce_losses = []\n",
    "    train_epoch_voc_losses = []\n",
    "    train_epoch_jsc_losses = []\n",
    "    train_epoch_ff_losses = []\n",
    "    train_loss = []\n",
    "    \n",
    "    epoch_pce_losses = []\n",
    "    epoch_voc_losses = []\n",
    "    epoch_jsc_losses = []\n",
    "    epoch_ff_losses = []\n",
    "    epoch_loss = []\n",
    "    \n",
    "    epoch_pce_accs = []\n",
    "    epoch_voc_accs = []\n",
    "    epoch_jsc_accs = []\n",
    "    epoch_ff_accs = []\n",
    "    epoch_accs = []\n",
    "\n",
    "    epoch_pce_r2s = []\n",
    "    epoch_voc_r2s = []\n",
    "    epoch_jsc_r2s = []\n",
    "    epoch_ff_r2s = []\n",
    "    epoch_r2s = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        train_losses = train.train_OPV_m2py_model(model = model,\n",
    "                                                training_data_set = train_dataloader,\n",
    "                                               criterion = criterion,\n",
    "                                               optimizer = optimizer)\n",
    "\n",
    "        train_epoch_pce_losses.append(train_losses[0])\n",
    "        train_epoch_voc_losses.append(train_losses[1])\n",
    "        train_epoch_jsc_losses.append(train_losses[2])\n",
    "        train_epoch_ff_losses.append(train_losses[3])\n",
    "        tot_trn_loss = sum(train_losses)\n",
    "        train_loss.append(tot_trn_loss)\n",
    "\n",
    "        test_losses, test_accs, test_r2s = test.eval_OPV_m2py_model(model = model,\n",
    "                                                                   test_data_set = test_dataloader,\n",
    "                                                                   criterion = criterion)\n",
    "\n",
    "        epoch_pce_losses.append(test_losses[0])\n",
    "        epoch_voc_losses.append(test_losses[1])\n",
    "        epoch_jsc_losses.append(test_losses[2])\n",
    "        epoch_ff_losses.append(test_losses[3])\n",
    "        tot_tst_loss = sum(test_losses)\n",
    "        epoch_loss.append(tot_tst_loss)\n",
    "        \n",
    "        epoch_pce_accs.append(test_accs[0])\n",
    "        epoch_voc_accs.append(test_accs[1])\n",
    "        epoch_jsc_accs.append(test_accs[2])\n",
    "        epoch_ff_accs.append(test_accs[3])\n",
    "        tot_tst_acc = sum(test_accs)\n",
    "        epoch_accs.append(tot_tst_acc)\n",
    "        \n",
    "        epoch_pce_r2s.append(test_r2s[0])\n",
    "        epoch_voc_r2s.append(test_r2s[1])\n",
    "        epoch_jsc_r2s.append(test_r2s[2])\n",
    "        epoch_ff_r2s.append(test_r2s[3])\n",
    "        tot_tst_r2 = sum(test_r2s)\n",
    "        epoch_r2s.append(tot_tst_r2)\n",
    "        \n",
    "        print('Finished epoch ', epoch)\n",
    "        \n",
    "    best_loss_indx = epoch_loss.index(min(epoch_loss))\n",
    "    best_acc_indx = epoch_accs.index(min(epoch_accs))\n",
    "    best_r2_indx = epoch_r2s.index(max(epoch_r2s))\n",
    "    \n",
    "    fit_results = {\n",
    "        'lr': lr,\n",
    "        'best_loss_epoch': best_loss_indx,\n",
    "        'best_acc_epoch': best_acc_indx,\n",
    "        'best_r2_epoch': best_r2_indx,\n",
    "        'pce_loss': epoch_pce_losses,\n",
    "        'voc_loss': epoch_voc_losses,\n",
    "        'jsc_loss': epoch_jsc_losses,\n",
    "        'ff_loss': epoch_ff_losses,\n",
    "        'test_losses': epoch_loss,        \n",
    "        'pce_acc': epoch_pce_accs,\n",
    "        'voc_acc': epoch_voc_accs,\n",
    "        'jsc_acc': epoch_jsc_accs,\n",
    "        'ff_acc': epoch_ff_accs,\n",
    "        'test_accs': epoch_accs,\n",
    "        'pce_r2': epoch_pce_r2s,\n",
    "        'voc_r2': epoch_voc_r2s,\n",
    "        'jsc_r2': epoch_jsc_r2s,\n",
    "        'ff_r2': epoch_ff_r2s,\n",
    "        'test_r2s': epoch_r2s,\n",
    "        'train_pce_loss': train_epoch_pce_losses,\n",
    "        'train_voc_loss': train_epoch_voc_losses,\n",
    "        'train_jsc_loss': train_epoch_jsc_losses,\n",
    "        'train_ff_loss': train_epoch_ff_losses\n",
    "    }\n",
    "\n",
    "    return fit_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = net.OPV_m2py_NN(8)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "lrs = np.linspace(1e-5, 1e-1, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "lr_opt = {}\n",
    "\n",
    "for i, lr in enumerate(lrs):\n",
    "    print(f'  optimization loop {i}')\n",
    "    print('-----------------------------')\n",
    "    \n",
    "    lr_opt[i] = fit(model, criterion, lr, epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./20200722_OPVNN4_hpo_results-r1.json', 'w') as fp:\n",
    "    json.dump(lr_opt, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f298729b4b0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../py-conjugated/'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "import morphology_networks as net\n",
    "import model_training as train\n",
    "import model_testing as test\n",
    "import physically_informed_loss_functions as pilf\n",
    "import network_utils as nuts\n",
    "\n",
    "torch.manual_seed(28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------\n",
    "# OPV NN7\n",
    "\n",
    "This model takes in all the available data for the 36 devices with associated atomic force microscopy data and m2py labels.\n",
    "\n",
    "There are 3 different datasets:\n",
    "- Tabular data with morphology summaries\n",
    "- m2py phase and domain labels (2 channels)\n",
    "- Fast force-distance mapping afm measurements (8 channels)\n",
    "----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bucket = 'sagemaker-us-east-2-362637960691'\n",
    "\n",
    "afm_data_path = 'py-conjugated/raw_data/OPV_npy/total_set/'\n",
    "afm_test_data_path = 'py-conjugated/raw_data/OPV_npy/test_set/'\n",
    "\n",
    "m2py_data_path = 'py-conjugated/m2py_labels/OPV_labels/total_set/'\n",
    "m2py_test_data_path = 'py-conjugated/m2py_labels/OPV_labels/test_set/'\n",
    "\n",
    "tabular_data_path = 'py-conjugated/tabular_data/OPV_train/'\n",
    "tabular_test_data_path = 'py-conjugated/tabular_data/OPV_test/'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "CV_afm_dict, CV_afm_label = nuts.load_s3_ims(data_bucket, afm_data_path)\n",
    "test_afm_dict, test_afm_label = nuts.load_s3_ims(data_bucket, afm_test_data_path)\n",
    "\n",
    "CV_m2py_dict, CV_m2py_label = nuts.load_s3_ims(data_bucket, m2py_data_path)\n",
    "test_m2py_dict, test_m2py_label = nuts.load_s3_ims(data_bucket, m2py_test_data_path)\n",
    "\n",
    "tabular_train_df = nuts.load_s3_df(data_bucket, tabular_data_path)\n",
    "tabular_test_df = nuts.load_s3_df(data_bucket, tabular_test_data_path)\n",
    "tabular_df = pd.concat([tabular_train_df, tabular_test_df])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold # 0\n",
      "-----------------------------\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 58800000000 bytes. Error code 12 (Cannot allocate memory)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-892ca2a2c71f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSmoothL1Loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOPV_total_NN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnuts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SageMaker/py-conjugated/py-conjugated/morphology_networks.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_dims)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         self.voc_predictor = nn.Sequential(\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m294000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_features, out_features, bias)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0min_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 58800000000 bytes. Error code 12 (Cannot allocate memory)"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "\n",
    "learning_rate = 1e-6\n",
    "num_epochs = 100\n",
    "\n",
    "cv_fits = {}\n",
    "\n",
    "kf = KFold(n_splits = 5)\n",
    "\n",
    "in_dims = int(tabular_df.shape[1]) #number of x channels\n",
    "\n",
    "#only need to run split on one of the 3 datasets, then can use the produced\n",
    "#indeces can be used for all 3 datasets to get the folds\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(CV_afm_dict, CV_afm_label)):\n",
    "    print(f'Fold # {fold}')\n",
    "    print('-----------------------------')\n",
    "    \n",
    "    train_dataset = nuts.OPV_CV_total_dataset(CV_afm_dict, CV_afm_label,\n",
    "                                              CV_m2py_dict, CV_m2py_label,\n",
    "                                              tabular_train_df, train_index)\n",
    "    \n",
    "    test_dataset = nuts.OPV_CV_total_dataset(CV_afm_dict, CV_afm_label,\n",
    "                                             CV_m2py_dict, CV_m2py_label,\n",
    "                                             tabular_train_df, test_index)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = len(train_index))\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = len(test_index))\n",
    "        \n",
    "    criterion = nn.SmoothL1Loss()\n",
    "        \n",
    "    model = net.OPV_total_NN(in_dims)\n",
    "    model.apply(nuts.init_weights)\n",
    "    \n",
    "    cv_fits[fold] = nuts.CV_OPV_total_fit(model, train_loader, test_loader, criterion,\n",
    "                                    lr = learning_rate, epochs = num_epochs)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('s3://sagemaker-us-east-2-362637960691/20200722_CNN3_hpo_results.json', 'w') as fp:\n",
    "with open('../ipynb/Networks/json/20200819_OPVNN4_CV_AdamW_opt_amsgrad.json', 'w') as fp:\n",
    "    json.dump(cv_fits, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../ipynb/Networks/json/20200819_OPVNN4_CV_AdamW_opt_amsgrad.json') as fp:\n",
    "    data = json.load(fp)\n",
    "    \n",
    "data['0'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fit_results(fit_dict):\n",
    "    lr = float(fit_dict['lr'])\n",
    "    best_loss_epoch = int(fit_dict['best_loss_epoch'])\n",
    "    best_acc_epoch = int(fit_dict['best_acc_epoch'])\n",
    "    best_r2_epoch = int(fit_dict['best_r2_epoch'])\n",
    "    \n",
    "    test_loss = [float(i) for i in fit_dict['test_losses']]\n",
    "    pce_loss = [float(i) for i in fit_dict['pce_loss']]\n",
    "    voc_loss = [float(i) for i in fit_dict['voc_loss']]\n",
    "    jsc_loss = [float(i) for i in fit_dict['jsc_loss']]\n",
    "    ff_loss = [float(i) for i in fit_dict['ff_loss']]\n",
    "    \n",
    "    test_acc = [float(i) for i in fit_dict['test_accs']]\n",
    "    pce_acc = [float(i) for i in fit_dict['pce_acc']]\n",
    "    voc_acc = [float(i) for i in fit_dict['voc_acc']]\n",
    "    jsc_acc = [float(i) for i in fit_dict['jsc_acc']]\n",
    "    ff_acc = [float(i) for i in fit_dict['ff_acc']]\n",
    "    \n",
    "    test_r2 = [float(i) for i in fit_dict['test_r2s']]\n",
    "    pce_r2 = [float(i) for i in fit_dict['pce_r2']]\n",
    "    voc_r2 = [float(i) for i in fit_dict['voc_r2']]\n",
    "    jsc_r2 = [float(i) for i in fit_dict['jsc_r2']]\n",
    "    ff_r2 = [float(i) for i in fit_dict['ff_r2']]\n",
    "    \n",
    "    train_pce_loss = [float(i) for i in fit_dict['train_pce_loss']]\n",
    "    train_voc_loss = [float(i) for i in fit_dict['train_voc_loss']]\n",
    "    train_jsc_loss = [float(i) for i in fit_dict['train_jsc_loss']]\n",
    "    train_ff_loss = [float(i) for i in fit_dict['train_ff_loss']]\n",
    "\n",
    "    epochs = np.arange(0, (len(test_loss)), 1)\n",
    "    \n",
    "    best_pce_index = pce_acc.index(min(pce_acc[:100]))\n",
    "    best_voc_index = voc_acc.index(min(voc_acc[:100]))\n",
    "    best_jsc_index = jsc_acc.index(min(jsc_acc[:100]))\n",
    "    best_ff_index = ff_acc.index(min(ff_acc[:100]))\n",
    "    \n",
    "#     best_pce_loss = pce_loss[best_pce_index]\n",
    "#     best_voc_loss = voc_loss[best_voc_index]\n",
    "#     best_jsc_loss = jsc_loss[best_jsc_index]\n",
    "#     best_ff_loss = ff_loss[best_ff_index]\n",
    "    \n",
    "#     best_pce_acc = pce_acc[best_pce_index]\n",
    "#     best_voc_acc = voc_acc[best_voc_index]\n",
    "#     best_jsc_acc = jsc_acc[best_jsc_index]\n",
    "#     best_ff_acc = ff_acc[best_ff_index]\n",
    "    \n",
    "#     best_pce_r2 = pce_r2[best_pce_index]\n",
    "#     best_voc_r2 = voc_r2[best_voc_index]\n",
    "#     best_jsc_r2 = jsc_r2[best_jsc_index]\n",
    "#     best_ff_r2 = ff_r2[best_ff_index]\n",
    "    \n",
    "    print(f\"PCE epoch: {best_pce_index}\")\n",
    "    print(f\"Voc epoch: {best_voc_index}\")\n",
    "    print(f\"Jsc epoch: {best_jsc_index}\")\n",
    "    print(f\"FF epoch: {best_ff_index}\")\n",
    "    \n",
    "#     print(f\"PCE Loss: {best_pce_loss}\")\n",
    "#     print(f\"Voc Loss: {best_voc_loss}\")\n",
    "#     print(f\"Jsc Loss: {best_jsc_loss}\")\n",
    "#     print(f\"FF Loss: {best_ff_loss}\")\n",
    "    \n",
    "#     print(f\"PCE MAPE: {best_pce_acc}\")\n",
    "#     print(f\"Voc MAPE: {best_voc_acc}\")\n",
    "#     print(f\"Jsc MAPE: {best_jsc_acc}\")\n",
    "#     print(f\"FF MAPE: {best_ff_acc}\")\n",
    "    \n",
    "#     print(f\"PCE R2: {best_pce_r2}\")\n",
    "#     print(f\"Voc R2: {best_voc_r2}\")\n",
    "#     print(f\"Jsc R2: {best_jsc_r2}\")\n",
    "#     print(f\"FF R2: {best_ff_r2}\")\n",
    "\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize = (12, 6))\n",
    "    ax1.plot(epochs, pce_loss, c = 'r', label = 'pce loss')\n",
    "    ax1.plot(epochs, voc_loss, c = 'g', label = 'voc loss')\n",
    "    ax1.plot(epochs, jsc_loss, c = 'b', label = 'jsc loss')\n",
    "    ax1.plot(epochs, ff_loss, c = 'c', label = 'ff loss')\n",
    "#     ax1.plot(epochs, test_loss, c = 'k', label = 'total loss')\n",
    "    ax1.plot(epochs, train_pce_loss, c = 'r', linestyle = '-.', label = 'pce train loss')\n",
    "    ax1.plot(epochs, train_voc_loss, c = 'g', linestyle = '-.', label = 'voc train loss')\n",
    "    ax1.plot(epochs, train_jsc_loss, c = 'b', linestyle = '-.', label = 'jsc train loss')\n",
    "#     ax1.plot(epochs, train_ff_loss, c = 'c', linestyle = '-.', label = 'ff train loss')\n",
    "    ax1.scatter(best_loss_epoch, min(test_loss[:100]), s = 64, c = 'c')\n",
    "    ax1.set_xlabel('Epochs')\n",
    "    ax1.set_ylabel('Mean Squared Error Loss')\n",
    "    ax1.legend(loc = 'best')\n",
    "    ax1.set_title(f'MSE Loss with lr = {lr}')\n",
    "\n",
    "    ax2.plot(epochs, pce_acc, c = 'r', label = 'pce acc')\n",
    "    ax2.plot(epochs, voc_acc, c = 'g', label = 'voc acc')\n",
    "    ax2.plot(epochs, jsc_acc, c = 'b', label = 'jsc acc')\n",
    "    ax2.plot(epochs, ff_acc, c = 'c', label = 'ff acc')\n",
    "#     ax2.plot(epochs, test_acc, c = 'k', label = 'total acc')\n",
    "    ax2.scatter(best_acc_epoch, min(test_acc[:100]), s = 64, c = 'c')\n",
    "    ax2.set_xlabel('Epochs')\n",
    "    ax2.set_ylabel('Mean Absolute Percent Error')\n",
    "    ax2.legend(loc = 'best')\n",
    "    ax2.set_title(f'MAPE with lr = {lr}')\n",
    "\n",
    "    ax3.plot(epochs, pce_r2, c = 'r', label = 'pce R$^2$')\n",
    "    ax3.plot(epochs, voc_r2, c = 'g', label = 'voc R$^2$')\n",
    "    ax3.plot(epochs, jsc_r2, c = 'b', label = 'jsc R$^2$')\n",
    "    ax3.plot(epochs, ff_r2, c = 'c', label = 'ff R$^2$')\n",
    "#     ax3.plot(epochs, test_r2, c = 'k', label = 'total R$^2$')\n",
    "    ax3.scatter(best_r2_epoch, max(test_r2[:100]), s = 64, c = 'c')\n",
    "    ax3.set_xlabel('Epochs')\n",
    "    ax3.set_ylabel('R$^2$')\n",
    "    ax3.legend(loc = 'best')\n",
    "    ax3.set_title(f'R$^2$ with lr = {lr}')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def report_metrics(fit_dict):\n",
    "    lr = float(fit_dict['lr'])\n",
    "    best_loss_epoch = int(fit_dict['best_loss_epoch'])\n",
    "    best_acc_epoch = int(fit_dict['best_acc_epoch'])\n",
    "    best_r2_epoch = int(fit_dict['best_r2_epoch'])\n",
    "    \n",
    "    test_loss = [float(i) for i in fit_dict['test_losses']]\n",
    "    pce_loss = [float(i) for i in fit_dict['pce_loss']]\n",
    "    voc_loss = [float(i) for i in fit_dict['voc_loss']]\n",
    "    jsc_loss = [float(i) for i in fit_dict['jsc_loss']]\n",
    "    ff_loss = [float(i) for i in fit_dict['ff_loss']]\n",
    "    \n",
    "    test_acc = [float(i) for i in fit_dict['test_accs']]\n",
    "    pce_acc = [float(i) for i in fit_dict['pce_acc']]\n",
    "    voc_acc = [float(i) for i in fit_dict['voc_acc']]\n",
    "    jsc_acc = [float(i) for i in fit_dict['jsc_acc']]\n",
    "    ff_acc = [float(i) for i in fit_dict['ff_acc']]\n",
    "    \n",
    "    test_r2 = [float(i) for i in fit_dict['test_r2s']]\n",
    "    pce_r2 = [float(i) for i in fit_dict['pce_r2']]\n",
    "    voc_r2 = [float(i) for i in fit_dict['voc_r2']]\n",
    "    jsc_r2 = [float(i) for i in fit_dict['jsc_r2']]\n",
    "    ff_r2 = [float(i) for i in fit_dict['ff_r2']]\n",
    "    \n",
    "    train_pce_loss = [float(i) for i in fit_dict['train_pce_loss']]\n",
    "    train_voc_loss = [float(i) for i in fit_dict['train_voc_loss']]\n",
    "    train_jsc_loss = [float(i) for i in fit_dict['train_jsc_loss']]\n",
    "    train_ff_loss = [float(i) for i in fit_dict['train_ff_loss']]\n",
    "    \n",
    "    best_pce_index = pce_acc.index(min(pce_acc[:100]))\n",
    "    best_voc_index = voc_acc.index(min(voc_acc[:100]))\n",
    "    best_jsc_index = jsc_acc.index(min(jsc_acc[:100]))\n",
    "    best_ff_index = ff_acc.index(min(ff_acc[:100]))\n",
    "    \n",
    "    best_pce_loss = pce_loss[best_pce_index]\n",
    "    best_voc_loss = voc_loss[best_voc_index]\n",
    "    best_jsc_loss = jsc_loss[best_jsc_index]\n",
    "    best_ff_loss = ff_loss[best_ff_index]\n",
    "    \n",
    "    losses = [best_pce_loss, best_voc_loss, best_jsc_loss, best_ff_loss]\n",
    "    \n",
    "    best_pce_acc = pce_acc[best_pce_index]\n",
    "    best_voc_acc = voc_acc[best_voc_index]\n",
    "    best_jsc_acc = jsc_acc[best_jsc_index]\n",
    "    best_ff_acc = ff_acc[best_ff_index]\n",
    "    \n",
    "    accs = [best_pce_acc, best_voc_acc, best_jsc_acc, best_ff_acc]\n",
    "\n",
    "    best_pce_r2 = pce_r2[best_pce_index]\n",
    "    best_voc_r2 = voc_r2[best_voc_index]\n",
    "    best_jsc_r2 = jsc_r2[best_jsc_index]\n",
    "    best_ff_r2 = ff_r2[best_ff_index]\n",
    "    \n",
    "    r2s = [best_pce_r2, best_voc_r2, best_jsc_r2, best_ff_r2]\n",
    "    \n",
    "    return losses, accs, r2s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "loss_summary = {}\n",
    "acc_summary = {}\n",
    "r2_summary = {}\n",
    "\n",
    "pce_loss = []\n",
    "pce_acc = []\n",
    "pce_r2 = []\n",
    "voc_loss = []\n",
    "voc_acc = []\n",
    "voc_r2 = []\n",
    "jsc_loss = []\n",
    "jsc_acc = []\n",
    "jsc_r2 = []\n",
    "ff_loss = []\n",
    "ff_acc = []\n",
    "ff_r2 = []\n",
    "\n",
    "\n",
    "for key, fit_dict in data.items():\n",
    "    plot_fit_results(fit_dict)\n",
    "    losses, accs, r2s = report_metrics(fit_dict)\n",
    "    \n",
    "    pce_loss.append(losses[0])\n",
    "    pce_acc.append(accs[0])\n",
    "    pce_r2.append(r2s[0])\n",
    "    \n",
    "    voc_loss.append(losses[1])\n",
    "    voc_acc.append(accs[1])\n",
    "    voc_r2.append(r2s[1])\n",
    "    \n",
    "    jsc_loss.append(losses[2])\n",
    "    jsc_acc.append(accs[2])\n",
    "    jsc_r2.append(r2s[2])\n",
    "    \n",
    "    ff_loss.append(losses[3])\n",
    "    ff_acc.append(accs[3])\n",
    "    ff_r2.append(r2s[3])\n",
    "    \n",
    "    \n",
    "loss_summary['PCE Worst'] = max(pce_loss)\n",
    "loss_summary['PCE Avg'] = sum(pce_loss)/len(pce_loss)\n",
    "loss_summary['PCE Best'] = min(pce_loss)\n",
    "\n",
    "loss_summary['Voc Worst'] = max(voc_loss)\n",
    "loss_summary['Voc Avg'] = sum(voc_loss)/len(voc_loss)\n",
    "loss_summary['Voc Best'] = min(voc_loss)\n",
    "\n",
    "loss_summary['Jsc Worst'] = max(jsc_loss)\n",
    "loss_summary['Jsc Avg'] = sum(jsc_loss)/len(jsc_loss)\n",
    "loss_summary['Jsc Best'] = min(jsc_loss)\n",
    "\n",
    "loss_summary['FF Worst'] = max(ff_loss)\n",
    "loss_summary['FF Avg'] = sum(ff_loss)/len(ff_loss)\n",
    "loss_summary['FF Best'] = min(ff_loss)\n",
    "\n",
    "acc_summary['PCE Worst'] = max(pce_acc)\n",
    "acc_summary['PCE Avg'] = sum(pce_acc)/len(pce_acc)\n",
    "acc_summary['PCE Best'] = min(pce_acc)\n",
    "\n",
    "acc_summary['Voc Worst'] = max(voc_acc)\n",
    "acc_summary['Voc Avg'] = sum(voc_acc)/len(voc_acc)\n",
    "acc_summary['Voc Best'] = min(voc_acc)\n",
    "\n",
    "acc_summary['Jsc Worst'] = max(jsc_acc)\n",
    "acc_summary['Jsc Avg'] = sum(jsc_acc)/len(jsc_acc)\n",
    "acc_summary['Jsc Best'] = min(jsc_acc)\n",
    "\n",
    "acc_summary['FF Worst'] = max(ff_acc)\n",
    "acc_summary['FF Avg'] = sum(ff_acc)/len(ff_acc)\n",
    "acc_summary['FF Best'] = min(ff_acc)\n",
    "\n",
    "r2_summary['PCE Worst'] = min(pce_r2)\n",
    "r2_summary['PCE Avg'] = sum(pce_r2)/len(pce_r2)\n",
    "r2_summary['PCE Best'] = max(pce_r2)\n",
    "\n",
    "r2_summary['Voc Worst'] = min(voc_r2)\n",
    "r2_summary['Voc Avg'] = sum(voc_r2)/len(voc_r2)\n",
    "r2_summary['Voc Best'] = max(voc_r2)\n",
    "\n",
    "r2_summary['Jsc Worst'] = min(jsc_r2)\n",
    "r2_summary['Jsc Avg'] = sum(jsc_r2)/len(jsc_r2)\n",
    "r2_summary['Jsc Best'] = max(jsc_r2)\n",
    "\n",
    "r2_summary['FF Worst'] = min(ff_r2)\n",
    "r2_summary['FF Avg'] = sum(ff_r2)/len(ff_r2)\n",
    "r2_summary['FF Best'] = max(ff_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorch\n",
    "from sagemaker.tuner import ContinuousParameter, HyperparameterTuner\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../py-conjugated/'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "import morphology_networks as net\n",
    "import model_training as train\n",
    "import model_testing as test\n",
    "import physically_informed_loss_functions as pilf\n",
    "import network_utils as nuts\n",
    "\n",
    "torch.manual_seed(28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bucket = 'sagemaker-us-east-2-362637960691'\n",
    "train_data_path = 'py-conjugated/m2py_labels/OPV_labels/train_set/'\n",
    "test_data_path = 'py-conjugated/m2py_labels/OPV_labels/test_set/'\n",
    "model_states_path = 's3://{}/py_conjugated/model_states/OPV/OPV_encoder_1/'.format(data_bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "train_dataset = nuts.OPV_ImDataset(data_bucket, train_data_path)\n",
    "test_dataset = nuts.OPV_ImDataset(data_bucket, test_data_path)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size = 26)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size = 10)\n",
    "\n",
    "print(len(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dims = int(x_train_tensor.size(1)) #number of x channels\n",
    "out_dims = y_test.shape[1] #number of predicted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, criterion, lr, epochs = 30):\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "    \n",
    "    train_epoch_pce_losses = []\n",
    "    train_epoch_voc_losses = []\n",
    "    train_epoch_jsc_losses = []\n",
    "    train_epoch_ff_losses = []\n",
    "    train_loss = []\n",
    "    \n",
    "    epoch_pce_losses = []\n",
    "    epoch_voc_losses = []\n",
    "    epoch_jsc_losses = []\n",
    "    epoch_ff_losses = []\n",
    "    epoch_loss = []\n",
    "    \n",
    "    epoch_pce_accs = []\n",
    "    epoch_voc_accs = []\n",
    "    epoch_jsc_accs = []\n",
    "    epoch_ff_accs = []\n",
    "    epoch_accs = []\n",
    "\n",
    "    epoch_pce_r2s = []\n",
    "    epoch_voc_r2s = []\n",
    "    epoch_jsc_r2s = []\n",
    "    epoch_ff_r2s = []\n",
    "    epoch_r2s = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        train_losses = train.train_OPV_m2py_model(model = model,\n",
    "                                                training_data_set = train_dataloader,\n",
    "                                               criterion = criterion,\n",
    "                                               optimizer = optimizer)\n",
    "\n",
    "        train_epoch_pce_losses.append(train_losses[0])\n",
    "        train_epoch_voc_losses.append(train_losses[1])\n",
    "        train_epoch_jsc_losses.append(train_losses[2])\n",
    "        train_epoch_ff_losses.append(train_losses[3])\n",
    "        tot_trn_loss = sum(train_losses)\n",
    "        train_loss.append(tot_trn_loss)\n",
    "\n",
    "        test_losses, test_accs, test_r2s = test.eval_OPV_m2py_model(model = model,\n",
    "                                                                   test_data_set = test_dataloader,\n",
    "                                                                   criterion = criterion)\n",
    "\n",
    "        epoch_pce_losses.append(test_losses[0])\n",
    "        epoch_voc_losses.append(test_losses[1])\n",
    "        epoch_jsc_losses.append(test_losses[2])\n",
    "        epoch_ff_losses.append(test_losses[3])\n",
    "        tot_tst_loss = sum(test_losses)\n",
    "        epoch_loss.append(tot_tst_loss)\n",
    "        \n",
    "        epoch_pce_accs.append(test_accs[0])\n",
    "        epoch_voc_accs.append(test_accs[1])\n",
    "        epoch_jsc_accs.append(test_accs[2])\n",
    "        epoch_ff_accs.append(test_accs[3])\n",
    "        tot_tst_acc = sum(test_accs)\n",
    "        epoch_accs.append(tot_tst_acc)\n",
    "        \n",
    "        epoch_pce_r2s.append(test_r2s[0])\n",
    "        epoch_voc_r2s.append(test_r2s[1])\n",
    "        epoch_jsc_r2s.append(test_r2s[2])\n",
    "        epoch_ff_r2s.append(test_r2s[3])\n",
    "        tot_tst_r2 = sum(test_r2s)\n",
    "        epoch_r2s.append(tot_tst_r2)\n",
    "        \n",
    "        print('Finished epoch ', epoch)\n",
    "        \n",
    "    best_loss_indx = epoch_loss.index(min(epoch_loss))\n",
    "    best_acc_indx = epoch_accs.index(min(epoch_accs))\n",
    "    best_r2_indx = epoch_r2s.index(max(epoch_r2s))\n",
    "    \n",
    "    fit_results = {\n",
    "        'lr': lr,\n",
    "        'best_loss_epoch': best_loss_indx,\n",
    "        'best_acc_epoch': best_acc_indx,\n",
    "        'best_r2_epoch': best_r2_indx,\n",
    "        'pce_loss': epoch_pce_losses,\n",
    "        'voc_loss': epoch_voc_losses,\n",
    "        'jsc_loss': epoch_jsc_losses,\n",
    "        'ff_loss': epoch_ff_losses,\n",
    "        'test_losses': epoch_loss,        \n",
    "        'pce_acc': epoch_pce_accs,\n",
    "        'voc_acc': epoch_voc_accs,\n",
    "        'jsc_acc': epoch_jsc_accs,\n",
    "        'ff_acc': epoch_ff_accs,\n",
    "        'test_accs': epoch_accs,\n",
    "        'pce_r2': epoch_pce_r2s,\n",
    "        'voc_r2': epoch_voc_r2s,\n",
    "        'jsc_r2': epoch_jsc_r2s,\n",
    "        'ff_r2': epoch_ff_r2s,\n",
    "        'test_r2s': epoch_r2s,\n",
    "        'train_pce_loss': train_epoch_pce_losses,\n",
    "        'train_voc_loss': train_epoch_voc_losses,\n",
    "        'train_jsc_loss': train_epoch_jsc_losses,\n",
    "        'train_ff_loss': train_epoch_ff_losses\n",
    "    }\n",
    "\n",
    "    return fit_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "lrs = np.linspace(0.01, 0.055, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "lr_opt = {}\n",
    "\n",
    "for i, lr in enumerate(lrs):\n",
    "    print(f'  optimization loop {i}')\n",
    "    print('-----------------------------')\n",
    "    \n",
    "    model = net.OPV_m2py_NN(8)\n",
    "    \n",
    "    lr_opt[i] = fit(model, criterion, lr, epochs = 15)\n",
    "    \n",
    "lr_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../ipynb/Networks/json/20200723_OPVNN4_hpo_results-r2.json', 'w') as fp:\n",
    "    json.dump(lr_opt, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------\n",
    "\n",
    "## After Hyperparameter optimization:\n",
    "\n",
    "The best model conditions are used to train a final, best performing model, which will be used to produce final results and figures. This is done in the following cells\n",
    "\n",
    "------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "# best_lr = 0.6057142857142856 \n",
    "# best_epochs = 5\n",
    "\n",
    "best_model = net.OPV_m2py_NN(8)\n",
    "best_model.apply(nuts.init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_results = fit(best_model, criterion, best_lr, best_epochs)\n",
    "\n",
    "with open('../ipynb/Networks/json/OPVNN4_best_results.json', 'w') as fp:\n",
    "    json.dump(best_results, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../ipynb/Networks/json/OPVNN4_best_results.json') as json_file:\n",
    "    results_json = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuts.plot_fit_results(best_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "best_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_dataloader:\n",
    "        \n",
    "        pce_pred, voc_pred, jsc_pred, ff_pred, im_enc = best_model(images)\n",
    "        \n",
    "\n",
    "mape = pilf.reg_MAPE()\n",
    "\n",
    "pce_mse = mean_squared_error(pce_pred.data.numpy(), labels[:,0].data.numpy())\n",
    "pce_r2 = r2_score(pce_pred.data.numpy(), labels[:,0].data.numpy())\n",
    "pce_mape = mape.forward(pce_pred.data.numpy(), labels[:,0].data.numpy())\n",
    "\n",
    "print(f'mse = {pce_mse}, mape = {pce_mape}, r2 = {pce_r2}')\n",
    "\n",
    "voc_mse = mean_squared_error(voc_pred.data.numpy(), labels[:,1].data.numpy())\n",
    "voc_r2 = r2_score(voc_pred.data.numpy(), labels[:,1].data.numpy())\n",
    "voc_mape = mape.forward(voc_pred.data.numpy(), labels[:,1].data.numpy())\n",
    "\n",
    "print(f'mse = {voc_mse}, mape = {voc_mape}, r2 = {voc_r2}')\n",
    "\n",
    "jsc_mse = mean_squared_error(jsc_pred.data.numpy(), labels[:,2].data.numpy())\n",
    "jsc_r2 = r2_score(jsc_pred.data.numpy(), labels[:,2].data.numpy())\n",
    "jsc_mape = mape.forward(jsc_pred.data.numpy(), labels[:,2].data.numpy())\n",
    "\n",
    "print(f'mse = {jsc_mse}, mape = {jsc_mape}, r2 = {jsc_r2}')\n",
    "\n",
    "ff_mse = mean_squared_error(ff_pred.data.numpy(), labels[:,3].data.numpy())\n",
    "ff_r2 = r2_score(ff_pred.data.numpy(), labels[:,3].data.numpy())\n",
    "ff_mape = mape.forward(ff_pred.data.numpy(), labels[:,3].data.numpy())\n",
    "\n",
    "print(f'mse = {ff_mse}, mape = {ff_mape}, r2 = {ff_r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuts.plot_OPV_parity(labels[:,0], pce_pred, labels[:,1], voc_pred,\n",
    "                     labels[:,2], jsc_pred, labels[:,3], ff_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

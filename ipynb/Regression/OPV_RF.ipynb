{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_train_df = pd.read_excel('/Users/wesleytatum/Desktop/py-conjugated/data/normed_OPV_device.xlsx')\n",
    "train_df = pd.read_excel('/Users/wesleytatum/Desktop/py-conjugated/data/normed_OPV_train.xlsx')\n",
    "test_df = pd.read_excel('/Users/wesleytatum/Desktop/py-conjugated/data/normed_OPV_test.xlsx')\n",
    "\n",
    "dev_only_x = dev_train_df[['Time (min)', 'Temp (C)']]\n",
    "dev_only_y = dev_train_df[['PCE', 'VocL', 'Jsc', 'FF']]\n",
    "x_train = train_df[['Anneal_time', 'Anneal_temp', 'MajorAL_avg', 'MinorAL_avg',\n",
    "                       'Ecc_avg', 'Orient_avg', 'Perim_avg']]\n",
    "y_train = train_df[['PCE', 'VocL', 'Jsc', 'FF']]\n",
    "x_test = test_df[['Anneal_time', 'Anneal_temp', 'MajorAL_avg', 'MinorAL_avg',\n",
    "                       'Ecc_avg', 'Orient_avg', 'Perim_avg']]\n",
    "y_test = test_df[['PCE', 'VocL', 'Jsc', 'FF']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After loading in the data and splitting it into our training and testing datasets, it's time for some curve fitting and hyper-parameter optimization. This notebook optimizes the Random Forest fitting on the above datasets\n",
    "\n",
    "First, we need to define some functions to train, optimize, and compare the Random Forest regression results for predicting the 4 different OPV device parameters, PCE, V$_{OC}$, J$_{SC}$, and FF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_up(n, decimals=1):\n",
    "    multiplier = 10 ** decimals\n",
    "    return math.ceil(n * multiplier) / multiplier\n",
    "\n",
    "\n",
    "def round_down(n, decimals=1):\n",
    "    multiplier = 10 ** decimals\n",
    "    return math.floor(n * multiplier) / multiplier\n",
    "\n",
    "\n",
    "def plot_parity(labels, predictions):\n",
    "    \"\"\"\n",
    "    This function calculates and plots the correlation values of labels and predictions.\n",
    "    An $R^{2}$ coefficient is calculated from these and annotates the plot.\n",
    "    \"\"\"\n",
    "    \n",
    "    upper = round_up(max(max(labels), max(predictions)))\n",
    "    lower = round_down(min(min(labels), min(predictions)))\n",
    "    \n",
    "    xlin = ylin = np.arange(upper, lower, 0.1)\n",
    "\n",
    "    r2 = r2_score(labels, predictions)\n",
    "    fig, ax = plt.subplots(figsize = (8,6))\n",
    "    plt.scatter(labels, predictions)\n",
    "    plt.plot(xlin, ylin, c = 'k')\n",
    "    ax.annotate(f\"$R^{2}$ = {r2:.3f}\", xy = (0.2, 0.4))\n",
    "    ax.set_xlim(lower, upper)\n",
    "    ax.set_ylim(lower, upper)\n",
    "    ax.set_xlabel(\"Predictions\")\n",
    "    ax.set_ylabel(\"Ground Truth\")\n",
    "    \n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "def mean_absolute_accuracy(labels, predictions):\n",
    "    \"\"\"\n",
    "    This is a function to calculate the % accuracy of a batch of labels and \n",
    "    predictions made by a model.\n",
    "    \"\"\"\n",
    "    \n",
    "    accuracies = []\n",
    "    for x, y in zip(predictions, labels):\n",
    "        accuracy = np.abs(((y - x) / y))\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "    mean_accuracy = sum(accuracies)/len(accuracies)\n",
    "        \n",
    "    return mean_accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_errors = []\n",
    "test_errors = []\n",
    "\n",
    "for i, d in enumerate(depths):\n",
    "    tree = DecisionTreeRegressor(max_depth = d)\n",
    "    tree.fit(x_train, y_train)\n",
    "#     print (tree.n_features_)\n",
    "#     print (tree.n_outputs_)\n",
    "\n",
    "    y_train_pred = tree.predict(x_train)\n",
    "    y_test_pred = tree.predict(x_test)\n",
    "\n",
    "\n",
    "    train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "    test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "    \n",
    "    train_errors.append(train_mse)\n",
    "    test_errors.append(test_mse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
